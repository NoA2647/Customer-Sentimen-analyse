{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "\n",
    "data = pd.read_csv('phone_user_review_file_1.csv',sep=\",\", encoding='Latin-1')\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"captuare english language data\"\"\"\n",
    "en_data = data[data['lang'] == 'en']\n",
    "\n",
    "\"\"\"first we remove NaN data from data set\"\"\"\n",
    "# rounding data for example 9.2 > 9 \n",
    "en_data = en_data.dropna().round()\n",
    "\n",
    "\n",
    "#sample data from dataset\n",
    "s_data = en_data[en_data['score'] == 1].copy()\n",
    "for i in range(2,11):\n",
    "    tmp = en_data[en_data['score'] == i].reset_index(drop=True)[:5000]\n",
    "    s_data = s_data.append(tmp, ignore_index=True)\n",
    "\n",
    "y = s_data['score'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y = list()\n",
    "for i in y:\n",
    "    if (i <= 3):\n",
    "        new_y.append('weak')\n",
    "    elif(i <= 6):\n",
    "        new_y.append('mid')\n",
    "    else:\n",
    "        new_y.append('good')\n",
    "    \n",
    "y = new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_finder(char):\n",
    "    \n",
    "    num = ord(char)\n",
    "    \n",
    "    if (num >= 65) and (num <= 90):\n",
    "        return chr(num+32)\n",
    "    if (num >= 97) and (num <= 122):\n",
    "        return char\n",
    "    if (num == 32) or (num == 39):\n",
    "        return char\n",
    "    return ''\n",
    "        \n",
    "\n",
    "def normalizer(text):\n",
    "    \"\"\"\n",
    "        we want remove other letter from text and just keep english letter\n",
    "        and lower case.\n",
    "    \"\"\"\n",
    "    map_list = map(new_finder, text)\n",
    "    text = ''.join(map_list)\n",
    "    \n",
    "    # tokenizing text and create list of the words\n",
    "    word_tokens = word_tokenize(text)\n",
    "    # stemming every words and and choose word if not in stopwords list\n",
    "    # and delete words that have lesss than 2 letter \n",
    "    filtered_sentence = [stemmer.stem(w) for w in word_tokens if not w in stop_words and len(w) > 2]\n",
    "    \n",
    "    # finally create string rest of this proccess!\n",
    "    filtered_sentence = ' '.join(filtered_sentence)[0:]\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(data):\n",
    "    data_text = data['extract'].tolist()\n",
    "    feature_list = list(map(normalizer,data_text))\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(feature_list):\n",
    "    X_dtm = vect.fit_transform(feature_list)\n",
    "    X_dtm = X_dtm.toarray()\n",
    "    return X_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(k, X_dtm, y):\n",
    "    global chi2_features\n",
    "    chi2_features = SelectKBest(chi2, k=k)\n",
    "    X_kbest_features = chi2_features.fit_transform(X_dtm, y)\n",
    "    return X_kbest_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc(data):\n",
    "    tokens = feature(data)\n",
    "    transform_data = vect.transform(tokens).toarray()\n",
    "    selection_feature = chi2_features.transform(transform_data)\n",
    "    return selection_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data , test_data , y_train, y_test = train_test_split(s_data, y, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dtm = vectorize(feature(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_dtm = vectorize(feature(train_data))\n",
    "X_train = feature_selection(4793, X_dtm, y_train)\n",
    "X_test = proc(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23335, 13128)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "predict_val_nb = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        good       0.83      0.85      0.84      3972\n",
      "         mid       0.62      0.66      0.64      2537\n",
      "        weak       0.59      0.47      0.52      1270\n",
      "\n",
      "    accuracy                           0.72      7779\n",
      "   macro avg       0.68      0.66      0.67      7779\n",
      "weighted avg       0.72      0.72      0.72      7779\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predict_val_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('phone_user_review_file_1.csv',sep=\",\", encoding='Latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='out.csv')\n",
    "new_data.to_csv('out.zip', index=False,\n",
    "          compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('out.csv',sep=\",\", encoding='Latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Plussaa: +Todella sulava kokemus arkikÃ\\x83Â¤ytÃ\\x83Â¶ssÃ\\x83Â¤ ilman tÃ\\x83Â¶kkimisiÃ\\x83Â¤ +Akku kestÃ\\x83Â¤Ã\\x83Â¤ kokopÃ\\x83Â¤ivÃ\\x83Â¤n vaikka pelaisikin paljon +Kamera Miinusta: -Bixby ja sen paikine -> Google assistant korvaa ja sovellus joka antaa remapata kyseisen napin -Ei stereo kaiutinta -Hinta MikÃ\\x83Â¤li hinta ei tunnu liian suolaiselta niin...'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['extract'][240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360802, 11)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
